{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b5f412e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install these packages if you haven't in the kernel \n",
    "# !pip install numpy opencv-python tensorflow keras\n",
    "# !pip install tensorflow\n",
    "# !pip install tensorflow-gpu\n",
    "# !pip install opencv-python\n",
    "# !pip install matplotlib\n",
    "# !pip install numpy\n",
    "# !pip install opencv-contrib-python \n",
    "# !pip install tensorflow-datasets\n",
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c776f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93781cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imagefolder (C:/Users/Bojana/.cache/huggingface/datasets/FER-Universe___imagefolder/FER-Universe--DiffusionFER-5e50418690f14861/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f292b8d47e41a3ad5b48bf817311f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"FER-Universe/DiffusionFER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "386b4ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 2581\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce9ae0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>{'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>{'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>{'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>{'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>{'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2581 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  image  label\n",
       "0     {'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...      0\n",
       "1     {'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...      0\n",
       "2     {'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...      0\n",
       "3     {'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...      0\n",
       "4     {'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...      0\n",
       "...                                                 ...    ...\n",
       "2576  {'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...      6\n",
       "2577  {'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...      6\n",
       "2578  {'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...      6\n",
       "2579  {'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...      6\n",
       "2580  {'bytes': None, 'path': 'C:\\Users\\Bojana\\.cach...      6\n",
       "\n",
       "[2581 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ds['train'].to_pandas()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0d2084e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Bojana\\\\.cache\\\\huggingface\\\\datasets\\\\downloads\\\\extracted\\\\e360db2d0f95f6b228b22417012e198ecdd834de8137740b583894ab9eccd85b\\\\angry\\\\aaaaaaaa_6.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0].image['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92cccf0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "4    698\n",
       "3    681\n",
       "6    364\n",
       "0    356\n",
       "1    176\n",
       "5    162\n",
       "2    144\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DOWNSAMPLING\n",
    "data['label'].value_counts() # classes are not equal  - we will cut them so there won't be a biased class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2a8cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_class_size = 144 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a64dbac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    144\n",
      "1    144\n",
      "2    144\n",
      "3    144\n",
      "4    144\n",
      "5    144\n",
      "6    144\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def downsample(df, label_column, n_samples):\n",
    "    return df.groupby(label_column).apply(lambda x: x.sample(n=n_samples, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "data = downsample(data, 'label', min_class_size)\n",
    "\n",
    "print(data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b571a5bd-d250-428d-bd9a-1568e63f0981",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     27\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 28\u001b[0m     img \u001b[38;5;241m=\u001b[39m extract_image_from_zip(image_path)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m         image_list\u001b[38;5;241m.\u001b[39mappend(img)  \u001b[38;5;66;03m# Add the extracted image to the list\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m, in \u001b[0;36mextract_image_from_zip\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_image_from_zip\u001b[39m(image_path):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Extract the zip file path and image name\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     parts \u001b[38;5;241m=\u001b[39m image_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m::\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m     zip_file_path \u001b[38;5;241m=\u001b[39m parts[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Path to the zip file\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     image_name_in_zip \u001b[38;5;241m=\u001b[39m parts[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzip://\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Image name inside zip\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# Open the zip file and extract the image\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_list = []\n",
    "\n",
    "def extract_image_from_zip(image_path):\n",
    "    # Extract the zip file path and image name\n",
    "    parts = image_path.split('::')\n",
    "    zip_file_path = parts[1]  # Path to the zip file\n",
    "    image_name_in_zip = parts[0].replace('zip://', '')  # Image name inside zip\n",
    "    \n",
    "    # Open the zip file and extract the image\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        with zip_ref.open(image_name_in_zip) as img_file:\n",
    "            try:\n",
    "                img = Image.open(img_file).convert('RGB')  # Convert to RGB\n",
    "                return np.array(img)  # Return image as NumPy array\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_name_in_zip} in {zip_file_path}: {e}\")\n",
    "                return None\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    image_path = row['image']['path']\n",
    "    img = extract_image_from_zip(image_path)\n",
    "    if img is not None:\n",
    "        image_list.append(img)  # Add the extracted image to the list\n",
    "\n",
    "# Example: Display the first extracted image\n",
    "if image_list:\n",
    "    plt.imshow(image_list[0])\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "270f6036-1c6f-4d0c-98f5-78eddce4ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image, interpolate=False ,target_size=(48, 48)):\n",
    "    # Resize image to the target size using OpenCV\n",
    "    if interpolate:\n",
    "        image_resized = cv2.resize(image, target_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "    else:\n",
    "        image_resized = cv2.resize(image, target_size)\n",
    "    return image_resized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "910cc92d-e76f-45d6-8d70-412efbc64143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(image):\n",
    "    return np.dot(image[...,:3], [0.2989, 0.5870, 0.1140])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9f3184c-1db2-4c1b-9bd2-fbcea93fbf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    return image / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1251b2f3-d2e6-4dc1-bc1e-aadbb91749bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_images = []\n",
    "for img in image_list:\n",
    "    img_resized = preprocess_image(img, true)\n",
    "    img_gray = convert_to_grayscale(img_resized)\n",
    "    img_normalized = normalize_image(img_gray)\n",
    "    array_images.append(img_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "92218cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1008"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(array_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a6d20956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_images[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196bc64f",
   "metadata": {},
   "source": [
    "# CREATING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aefef98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "#from keras.utils import np_utils\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "80b29f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 6, 6, 6], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array(array_images)\n",
    "Y = np.array(data['label'])\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "70e23ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "641ee0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 64\n",
    "num_labels = 7\n",
    "batch_size = 128\n",
    "epochs = 40\n",
    "width, height = 48, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "12307c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes=num_labels)\n",
    "Y_test = to_categorical(Y_test, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "925f2892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.02239725, 0.1341298 , ..., 0.15951176,\n",
       "         0.06728275, 0.60358392],\n",
       "        [0.07806118, 0.08383725, 0.1188498 , ..., 0.06176039,\n",
       "         0.11184157, 0.29192275],\n",
       "        [0.08473137, 0.01645216, 0.04159843, ..., 0.05666706,\n",
       "         0.06220745, 0.04260157],\n",
       "        ...,\n",
       "        [0.26460588, 0.39087569, 0.44637059, ..., 0.32536235,\n",
       "         0.32883647, 0.34524627],\n",
       "        [0.48586039, 0.52394235, 0.55401294, ..., 0.32928353,\n",
       "         0.33667882, 0.35191647],\n",
       "        [0.60240824, 0.62476314, 0.62314392, ..., 0.33231059,\n",
       "         0.34637608, 0.35975882]],\n",
       "\n",
       "       [[0.36933294, 0.39241294, 0.40575333, ..., 0.45600353,\n",
       "         0.44031882, 0.41359569],\n",
       "        [0.37717529, 0.39908314, 0.41129373, ..., 0.46635922,\n",
       "         0.45046314, 0.42418706],\n",
       "        [0.38893882, 0.40462353, 0.42422941, ..., 0.47028039,\n",
       "         0.45992471, 0.44031882],\n",
       "        ...,\n",
       "        [0.41348667, 0.0528298 , 0.0427702 , ..., 0.13312627,\n",
       "         0.11537529, 0.0863502 ],\n",
       "        [0.40059333, 0.02069333, 0.06395294, ..., 0.12600902,\n",
       "         0.10753294, 0.08008471],\n",
       "        [0.40566863, 0.01681451, 0.05796549, ..., 0.1013098 ,\n",
       "         0.07499137, 0.07616353]],\n",
       "\n",
       "       [[0.20411255, 0.23867804, 0.28019176, ..., 0.19234902,\n",
       "         0.13975451, 0.04272824],\n",
       "        [0.27518314, 0.22113843, 0.19138824, ..., 0.21402118,\n",
       "         0.17941333, 0.15705843],\n",
       "        [0.22691451, 0.24769255, 0.22853373, ..., 0.17783647,\n",
       "         0.15471412, 0.1888749 ],\n",
       "        ...,\n",
       "        [0.39285059, 0.44369922, 0.48335804, ..., 0.58325216,\n",
       "         0.57496275, 0.56712039],\n",
       "        [0.45407922, 0.50667373, 0.46492431, ..., 0.08995137,\n",
       "         0.17807216, 0.40545804],\n",
       "        [0.51108431, 0.54520275, 0.53412196, ..., 0.0860302 ,\n",
       "         0.08995137, 0.09824078]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.50971529, 0.34232941, 0.30596902, ..., 0.03503765,\n",
       "         0.05072235, 0.35471294],\n",
       "        [0.5347102 , 0.41328039, 0.55293294, ..., 0.03912784,\n",
       "         0.04332706, 0.06397843],\n",
       "        [0.51186588, 0.53426314, 0.28957686, ..., 0.03868078,\n",
       "         0.04652314, 0.06996588],\n",
       "        ...,\n",
       "        [0.76294039, 0.81841059, 0.84310941, ..., 0.09025451,\n",
       "         0.02235529, 0.00279137],\n",
       "        [0.85250431, 0.87089569, 0.87477451, ..., 0.12424627,\n",
       "         0.12772039, 0.0566251 ],\n",
       "        [0.85783333, 0.85738627, 0.86333137, ..., 0.17901608,\n",
       "         0.20759412, 0.21980471]],\n",
       "\n",
       "       [[0.44686275, 0.47107255, 0.48765137, ..., 0.43307529,\n",
       "         0.41067804, 0.3887702 ],\n",
       "        [0.4711149 , 0.48583882, 0.51256196, ..., 0.44831294,\n",
       "         0.42664078, 0.40720392],\n",
       "        [0.48673294, 0.50561373, 0.52869373, ..., 0.4736949 ,\n",
       "         0.44831294, 0.42983686],\n",
       "        ...,\n",
       "        [0.58220667, 0.55823255, 0.62489255, ..., 0.03808196,\n",
       "         0.02862039, 0.06928235],\n",
       "        [0.56696902, 0.56724706, 0.62764157, ..., 0.02627608,\n",
       "         0.01943686, 0.08102157],\n",
       "        [0.55011216, 0.58220667, 0.60690588, ..., 0.03141176,\n",
       "         0.01248863, 0.34531725]],\n",
       "\n",
       "       [[0.65708863, 0.64483569, 0.69355137, ..., 0.55852745,\n",
       "         0.51656667, 0.44828745],\n",
       "        [0.68129843, 0.69193216, 0.71153804, ..., 0.54373686,\n",
       "         0.5283302 , 0.48519725],\n",
       "        [0.70991882, 0.65939059, 0.70761686, ..., 0.57001294,\n",
       "         0.56010431, 0.54603882],\n",
       "        ...,\n",
       "        [0.51730941, 0.54290275, 0.57358941, ..., 0.29655176,\n",
       "         0.27302471, 0.33544314],\n",
       "        [0.53461333, 0.53069216, 0.54840078, ..., 0.26914588,\n",
       "         0.29145843, 0.28478824],\n",
       "        [0.50207176, 0.52911529, 0.54452196, ..., 0.25486902,\n",
       "         0.27788235, 0.27125451]]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "aca94cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "264c1cf7-c30e-4cc3-a626-4cee179c56e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(806, 48, 48, 1)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cad65eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkuzm\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e8763a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,098,176</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,175</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │         \u001b[38;5;34m147,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │       \u001b[38;5;34m2,098,176\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │           \u001b[38;5;34m7,175\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,345,607</span> (8.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,345,607\u001b[0m (8.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,345,607</span> (8.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,345,607\u001b[0m (8.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbbcae",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7d5e8df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "759c5ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkuzm\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.7941 - loss: 0.6027  \n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkuzm\\anaconda3\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8677 - loss: 0.4012  \n",
      "Epoch 3/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8792 - loss: 0.3639  \n",
      "Epoch 4/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8968 - loss: 0.3152  \n",
      "Epoch 5/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9104 - loss: 0.2940  \n",
      "Epoch 6/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9206 - loss: 0.2629  \n",
      "Epoch 7/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9056 - loss: 0.2597  \n",
      "Epoch 8/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9138 - loss: 0.2537  \n",
      "Epoch 9/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9263 - loss: 0.2458  \n",
      "Epoch 10/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9362 - loss: 0.2076  \n",
      "Epoch 11/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9184 - loss: 0.2294  \n",
      "Epoch 12/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9240 - loss: 0.2121  \n",
      "Epoch 13/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9311 - loss: 0.2124  \n",
      "Epoch 14/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9305 - loss: 0.2144  \n",
      "Epoch 15/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9252 - loss: 0.1952  \n",
      "Epoch 16/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9462 - loss: 0.1754  \n",
      "Epoch 17/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9504 - loss: 0.1423  \n",
      "Epoch 18/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9452 - loss: 0.1707  \n",
      "Epoch 19/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9556 - loss: 0.1381  \n",
      "Epoch 20/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9542 - loss: 0.1306  \n",
      "Epoch 21/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9578 - loss: 0.1218  \n",
      "Epoch 22/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9677 - loss: 0.1289  \n",
      "Epoch 23/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9610 - loss: 0.1219  \n",
      "Epoch 24/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9513 - loss: 0.1288  \n",
      "Epoch 25/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9590 - loss: 0.1099  \n",
      "Epoch 26/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9556 - loss: 0.1321  \n",
      "Epoch 27/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9729 - loss: 0.0888  \n",
      "Epoch 28/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9631 - loss: 0.1153  \n",
      "Epoch 29/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9571 - loss: 0.1321  \n",
      "Epoch 30/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9555 - loss: 0.1408  \n",
      "Epoch 31/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9627 - loss: 0.1209  \n",
      "Epoch 32/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9747 - loss: 0.0867  \n",
      "Epoch 33/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9737 - loss: 0.0932  \n",
      "Epoch 34/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9596 - loss: 0.1008  \n",
      "Epoch 35/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9736 - loss: 0.0933  \n",
      "Epoch 36/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9642 - loss: 0.0931  \n",
      "Epoch 37/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9729 - loss: 0.0949  \n",
      "Epoch 38/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9729 - loss: 0.0815  \n",
      "Epoch 39/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9739 - loss: 0.0811  \n",
      "Epoch 40/40\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9624 - loss: 0.1122  \n"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(X_train, Y_train, batch_size=batch_size)\n",
    "model.compile(loss='categorical_crossentropy'\n",
    ", optimizer=keras.optimizers.Adam()\n",
    ", metrics=['accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=batch_size,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2c1e8f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4b399b96-9111-408f-90f6-589375d57599",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "910571c1-d543-45b4-9df1-c88393391a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "eef9068f-4fe2-4b0d-bfba-0df9483f8a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model:  0.4504950495049505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ac=accuracy_score(Y_test.round(), y_pred.round())\n",
    "print('accuracy of the model: ',ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15c113b-6a37-498c-8639-287c919395d1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmotionDetectionImageModel.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(\"EmotionDetectionImageModel.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b9a166",
   "metadata": {},
   "source": [
    "# Training the model with a new dataset\n",
    "The dataset used is downloaded locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b8d57f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import os\n",
    "\n",
    "model = load_model(\"EmotionDetectionImageModel.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2167803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"0\", \"1\", \"2\", \"3\", \"4\",  \"5\", \"6\"] # emotions are classiffied in numbers 0 - anger, 1 - fear .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9455b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:/Users/Bojana/Downloads/practice/train/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d0cd238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for category in classes:\n",
    "    path = os.path.join(data_dir, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_arr = cv2.imread(os.path.join(path, img))\n",
    "        plt.imshow(cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB))\n",
    "        plt.show()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9d68be12",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in classes:\n",
    "        path = os.path.join(data_dir, category)\n",
    "        class_num = classes.index(category)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                img_arr = cv2.imread(os.path.join(path, img))\n",
    "                img_resized = preprocess_image(img_arr)\n",
    "                img_gray = convert_to_grayscale(img_resized)\n",
    "                img_normalized = normalize_image(img_gray)\n",
    "                training_data.append([img_normalized, class_num])\n",
    "            except Exception as e:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "76888327",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6f267567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32880\n"
     ]
    }
   ],
   "source": [
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "66970234",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for features, label in training_data:\n",
    "    X.append(features)\n",
    "    Y.append(label)\n",
    "    \n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "981685de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32880, 48, 48)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "563d830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "21e60768",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(Y_train, num_classes=num_labels)\n",
    "Y_test = to_categorical(Y_test, num_classes=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7eb553dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26304, 7)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "8beb038c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6576, 48, 48)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bf950e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26304, 48, 48, 1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(-1, 48,48,1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c7ad441c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6576, 48, 48, 1)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape(-1, 48,48,1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "96ded0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bojana\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 545ms/step - accuracy: 0.2194 - loss: 2.0571\n",
      "Epoch 2/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 327ms/step - accuracy: 0.3700 - loss: 1.6120\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bojana\\anaconda3\\Lib\\contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 499ms/step - accuracy: 0.4054 - loss: 1.5154\n",
      "Epoch 4/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 318ms/step - accuracy: 0.4525 - loss: 1.4281\n",
      "Epoch 5/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 549ms/step - accuracy: 0.4750 - loss: 1.3706\n",
      "Epoch 6/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 322ms/step - accuracy: 0.4948 - loss: 1.3272\n",
      "Epoch 7/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 472ms/step - accuracy: 0.5110 - loss: 1.2733\n",
      "Epoch 8/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 295ms/step - accuracy: 0.5326 - loss: 1.2236\n",
      "Epoch 9/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 486ms/step - accuracy: 0.5406 - loss: 1.2018\n",
      "Epoch 10/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 305ms/step - accuracy: 0.5597 - loss: 1.1497\n",
      "Epoch 11/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 544ms/step - accuracy: 0.5728 - loss: 1.1249\n",
      "Epoch 12/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 321ms/step - accuracy: 0.5893 - loss: 1.0816\n",
      "Epoch 13/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 535ms/step - accuracy: 0.5890 - loss: 1.0809\n",
      "Epoch 14/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 315ms/step - accuracy: 0.6046 - loss: 1.0424\n",
      "Epoch 15/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 483ms/step - accuracy: 0.6096 - loss: 1.0215\n",
      "Epoch 16/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 314ms/step - accuracy: 0.6185 - loss: 1.0094\n",
      "Epoch 17/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 501ms/step - accuracy: 0.6237 - loss: 0.9917\n",
      "Epoch 18/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 301ms/step - accuracy: 0.6452 - loss: 0.9442\n",
      "Epoch 19/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 523ms/step - accuracy: 0.6570 - loss: 0.9176\n",
      "Epoch 20/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 301ms/step - accuracy: 0.6646 - loss: 0.9027\n",
      "Epoch 21/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 507ms/step - accuracy: 0.6706 - loss: 0.8738\n",
      "Epoch 22/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 296ms/step - accuracy: 0.6948 - loss: 0.8419\n",
      "Epoch 23/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 537ms/step - accuracy: 0.6869 - loss: 0.8393\n",
      "Epoch 24/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 337ms/step - accuracy: 0.6972 - loss: 0.8049\n",
      "Epoch 25/25\n",
      "\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 554ms/step - accuracy: 0.6992 - loss: 0.7966\n"
     ]
    }
   ],
   "source": [
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(X_train, Y_train, batch_size=batch_size)\n",
    "model.compile(loss='categorical_crossentropy'\n",
    "                , optimizer=keras.optimizers.Adam()\n",
    "                , metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=batch_size,\n",
    "    epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5d539b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m206/206\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 62ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d761ad53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model:  0.4530109489051095\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "ac=accuracy_score(Y_test.round(), y_pred.round())\n",
    "print('accuracy of the model: ',ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c424c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"EmotionDetectionImageModel.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
